FROM bde2020/spark-worker:3.0.0-hadoop3.2

USER root

# Installer Java 11 et les dépendances
RUN set -eux; \
    if command -v apt-get >/dev/null 2>&1; then \
      apt-get update && apt-get install -y openjdk-11-jdk curl ca-certificates && rm -rf /var/lib/apt/lists/*; \
    elif command -v apk >/dev/null 2>&1; then \
      apk add --no-cache openjdk11 curl ca-certificates; \
    else \
      echo "No supported package manager found" && exit 1; \
    fi

ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk

RUN set -eux; \
    if command -v apt-get >/dev/null 2>&1; then \
      apt-get update && apt-get install -y curl ca-certificates && rm -rf /var/lib/apt/lists/*; \
    elif command -v apk >/dev/null 2>&1; then \
      apk add --no-cache curl ca-certificates; \
    else \
      echo "No supported package manager found" && exit 1; \
    fi

RUN set -eux; \
    mkdir -p /spark/jars; \
    curl -L -o /spark/jars/postgresql-42.2.27.jar https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.27/postgresql-42.2.27.jar

# Copier la configuration Hive pour que Spark puisse créer les tables
COPY configs/hive-site.xml /spark/conf/hive-site.xml
